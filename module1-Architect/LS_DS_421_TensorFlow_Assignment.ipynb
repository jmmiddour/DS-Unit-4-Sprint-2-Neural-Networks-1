{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_432_TensorFlow_Assignment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyHCH8HvHSf"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# *Data Science Unit 4 Sprint 2 Assignment 1*\n",
        "\n",
        "Use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Please build a baseline classification model then run a few experiments with different optimizers and learning rates. \n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Tc3ovEyQ9b"
      },
      "source": [
        "## Load Your Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkU0pAYCvU8o",
        "outputId": "b8308ce5-816c-4e2f-e2d4-5827c9430528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "\n",
        "data = np.load('quickdraw10.npz')\n",
        "X = data['arr_0']\n",
        "y = data['arr_1']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 784)\n",
            "(100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qsDqdqvHDd"
      },
      "source": [
        "class_names = ['apple',\n",
        " 'anvil',\n",
        " 'airplane',\n",
        " 'banana',\n",
        " 'The Eiffel Tower',\n",
        " 'The Mona Lisa',\n",
        " 'The Great Wall of China',\n",
        " 'alarm clock',\n",
        " 'ant',\n",
        " 'asparagus']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owbm1EbxvA5A",
        "outputId": "53386873-944c-4491-bd02-bda2238169d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "start = 0\n",
        "\n",
        "for num, name in enumerate(class_names):\n",
        "    plt.subplot(2,5, num+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X[start].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(name)\n",
        "    start += 10000\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c97_M1WNvTNY"
      },
      "source": [
        "# Need this line to randomly shuffle both the X & y at the same time.\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRMUuSdl3NBQ",
        "outputId": "608a58bb-4ab2-4b92-b74d-2ea3b9a125a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X.shape, y.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 784) (100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvYXA8Qz32Q9",
        "outputId": "30aad888-1db8-4502-8c86-3e2d9ca84e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X[3]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,  11, 101,   4,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0, 158, 255,  99,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  80, 255, 241, 221,   5,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  21, 232, 197,  70, 255,\n",
              "        99,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 179, 244,  37,\n",
              "         0, 198, 224,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 255,\n",
              "       206, 204, 235, 255, 255, 245, 153,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  33,\n",
              "       242, 183, 147, 221, 255, 220, 228, 241,  70,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         3, 196, 234,  23,  82, 255, 201,   1,  67, 255,  85,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0, 122, 255,  84,  35, 237, 252, 144,   0,   1, 226, 166,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  48, 249, 158,   3, 197, 233, 186, 237,  21,   0,\n",
              "       148, 240,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   7, 210, 223,  14, 117, 255,  84,  36, 247,\n",
              "       159,   0,  69, 255,  70,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0, 141, 253,  63,  40, 246, 165,   0,\n",
              "         0, 126, 254,  74,   5, 239, 154,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  61, 253, 146,  89, 234, 251,\n",
              "       218, 223, 238, 248, 255, 255,  55, 150, 243,  15,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  15, 224, 218, 248, 255,\n",
              "       255, 201, 161, 153, 136, 128, 155, 255, 104,  42, 254, 109,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 161, 248,  49,\n",
              "       117, 249, 163,   0,   0,   0,   0,   0,   0, 200, 207,   0, 191,\n",
              "       215,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 255,\n",
              "       175, 109, 197, 244,  92,  68,  58,  55,  85, 121, 156, 216, 255,\n",
              "       247, 107, 255,  68,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       158, 240, 240, 255, 255, 255, 255, 255, 255, 255, 255, 253, 224,\n",
              "       195, 255, 173,   9, 228, 174,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,  20, 246, 142,   0, 129, 253,  63,  77, 173, 231, 242, 241,\n",
              "       235, 141,   6, 211, 178,   0, 127, 251,  29,   0,   0,   0,   0,\n",
              "         0,   0,   0, 112, 253,  35,   1, 227, 177,  74, 245, 238, 168,\n",
              "       153, 153, 168, 253, 154, 141, 244,   7,  25, 250, 132,   0,   0,\n",
              "         0,   0,   0,   0,   3, 198, 208,   0,   5, 255, 117, 181, 218,\n",
              "        18,   0,   0,   0,   0, 148, 243,  78, 255,  64,  14, 193, 244,\n",
              "       155,   5,   0,   0,   0,  65, 227, 255, 255, 222, 149, 254, 128,\n",
              "       222, 158,   0,   0,   0,   0,   0,  89, 255, 117, 252, 232, 252,\n",
              "       255, 255, 210,   7,   0,   0,   0,  80, 201, 255, 133, 169, 239,\n",
              "       255, 251, 255, 212,  49,   0,   0,   0,   0,  81, 255, 255, 244,\n",
              "       197, 120,  61, 211, 189,   0,   0,   0,   8, 196, 241, 255, 201,\n",
              "       118,  58, 231, 208, 255, 215,  67,   0,   0,   0,   0,  73, 255,\n",
              "        83,   1,   0,   0,   0, 155, 221,   0,   0,   0,   3, 141, 159,\n",
              "       151, 196, 253, 255, 255, 255, 241,  19,   0,   0,   0,   0,   0,\n",
              "        95, 255,  49,   8,   7,  64, 129, 222, 232,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,  24,  73,  85,  88,  48,   0,   0,   0,   0,\n",
              "         0,   0, 117, 255, 255, 255, 255, 255, 249, 195, 102,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   2,  72, 102, 117, 117,  70,  11,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQyvTPoORUZl",
        "outputId": "62b798ee-7477-461d-c8c0-24f26d8d2d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[3]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLm52YQi4FTJ",
        "outputId": "6ce1c7e2-768c-427a-d0ad-d14508bd0a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# # Flatten to turn all numbers into 0 thru 1 to normalize\n",
        "# X = X.astype('float32') /255\n",
        "# y = y.astype('float32') /255\n",
        "# X[3]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.1882353 , 0.7294118 , 0.73333335,\n",
              "       0.5568628 , 0.38431373, 0.20392157, 0.03921569, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.60784316, 0.94509804, 0.7647059 , 0.9372549 , 1.        ,\n",
              "       1.        , 0.9882353 , 0.85490197, 0.6745098 , 0.49803922,\n",
              "       0.26666668, 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.03529412, 0.8392157 , 0.9607843 ,\n",
              "       0.14509805, 0.        , 0.11764706, 0.29411766, 0.47058824,\n",
              "       0.64705884, 0.8235294 , 0.98039216, 1.        , 0.96862745,\n",
              "       0.74509805, 0.48235294, 0.22352941, 0.01568628, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.42352942, 1.        , 1.        , 0.9882353 , 0.8745098 ,\n",
              "       0.8666667 , 0.9137255 , 0.92941177, 0.92941177, 0.7411765 ,\n",
              "       0.4509804 , 0.3529412 , 0.52156866, 0.78431374, 0.9882353 ,\n",
              "       1.        , 0.9490196 , 0.7647059 , 0.6745098 , 0.5803922 ,\n",
              "       0.49411765, 0.40392157, 0.30980393, 0.22745098, 0.07843138,\n",
              "       0.        , 0.        , 0.        , 0.48235294, 1.        ,\n",
              "       0.8980392 , 0.47058824, 0.7529412 , 0.9647059 , 1.        ,\n",
              "       0.8980392 , 1.        , 0.83137256, 0.99607843, 1.        ,\n",
              "       0.80784315, 0.5411765 , 0.41960785, 0.5176471 , 0.8627451 ,\n",
              "       0.972549  , 0.87058824, 0.9254902 , 0.9843137 , 1.        ,\n",
              "       1.        , 1.        , 0.9411765 , 0.16862746, 0.        ,\n",
              "       0.        , 0.45882353, 1.        , 0.99607843, 0.13725491,\n",
              "       0.8352941 , 1.        , 0.5882353 , 0.15294118, 1.        ,\n",
              "       0.9843137 , 0.27450982, 0.42352942, 0.7294118 , 0.98039216,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99607843,\n",
              "       1.        , 0.34901962, 0.        , 0.        , 0.33333334,\n",
              "       1.        , 1.        , 0.8980392 , 0.96862745, 1.        ,\n",
              "       0.56078434, 0.9019608 , 0.99607843, 0.88235295, 0.02745098,\n",
              "       0.        , 0.14901961, 0.99607843, 1.        , 0.8156863 ,\n",
              "       0.3647059 , 0.99215686, 0.50980395, 0.2       , 0.2       ,\n",
              "       0.16470589, 0.43137255, 1.        , 0.8901961 , 0.01960784,\n",
              "       0.        , 0.        , 0.1882353 , 1.        , 0.99607843,\n",
              "       0.93333334, 0.2901961 , 0.99215686, 1.        , 0.75686276,\n",
              "       0.5921569 , 0.98039216, 0.09411765, 0.5019608 , 0.9764706 ,\n",
              "       1.        , 0.654902  , 0.00392157, 0.01960784, 0.89411765,\n",
              "       0.6431373 , 0.        , 0.        , 0.        , 0.5254902 ,\n",
              "       0.98039216, 0.2901961 , 0.        , 0.        , 0.        ,\n",
              "       0.10196079, 1.        , 0.9137255 , 0.7294118 , 0.90588236,\n",
              "       0.9843137 , 0.8156863 , 0.00392157, 0.21176471, 1.        ,\n",
              "       0.91764706, 0.99215686, 0.63529414, 0.89411765, 0.6509804 ,\n",
              "       0.39215687, 0.87058824, 1.        , 0.90588236, 0.3764706 ,\n",
              "       0.74509805, 0.23137255, 0.72156864, 0.7764706 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08235294, 1.        ,\n",
              "       0.8784314 , 0.99607843, 0.827451  , 0.6431373 , 0.92156863,\n",
              "       0.14117648, 0.7176471 , 1.        , 0.9254902 , 0.21176471,\n",
              "       0.01960784, 0.7490196 , 0.99215686, 1.        , 0.7764706 ,\n",
              "       0.7647059 , 1.        , 1.        , 0.79607844, 0.15294118,\n",
              "       0.91764706, 0.5764706 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.05882353, 1.        , 0.99607843, 0.99607843,\n",
              "       0.08627451, 0.40784314, 1.        , 0.972549  , 0.93333334,\n",
              "       0.76862746, 0.9411765 , 0.40784314, 0.87058824, 1.        ,\n",
              "       1.        , 0.78431374, 0.96862745, 0.9882353 , 1.        ,\n",
              "       0.52156866, 0.        , 0.12156863, 1.        , 0.38039216,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.03137255,\n",
              "       1.        , 0.89411765, 1.        , 0.4862745 , 0.89411765,\n",
              "       1.        , 0.7529412 , 0.08235294, 0.22745098, 1.        ,\n",
              "       1.        , 0.75686276, 0.45882353, 0.99607843, 0.9764706 ,\n",
              "       0.56078434, 0.12941177, 0.8980392 , 0.6117647 , 0.        ,\n",
              "       0.3137255 , 1.        , 0.1882353 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.9647059 , 0.5921569 ,\n",
              "       0.9764706 , 1.        , 0.80784315, 0.93333334, 0.67058825,\n",
              "       0.02745098, 0.6901961 , 1.        , 0.8627451 , 0.43529412,\n",
              "       0.9843137 , 0.9372549 , 0.8784314 , 0.        , 0.        ,\n",
              "       0.64705884, 0.8862745 , 0.01176471, 0.43137255, 1.        ,\n",
              "       0.04705882, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.8117647 , 0.7529412 , 0.9529412 , 0.9764706 ,\n",
              "       0.05882353, 0.49411765, 0.9882353 , 0.4745098 , 0.9882353 ,\n",
              "       0.6627451 , 0.99215686, 1.        , 0.64705884, 0.39607844,\n",
              "       1.        , 0.16470589, 0.        , 0.28235295, 1.        ,\n",
              "       0.31764707, 0.5058824 , 0.972549  , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.6627451 ,\n",
              "       0.83137256, 0.20784314, 1.        , 0.38431373, 0.07058824,\n",
              "       0.95686275, 0.59607846, 0.14509805, 0.07450981, 0.92156863,\n",
              "       0.78039217, 0.        , 0.07450981, 0.89411765, 0.23137255,\n",
              "       0.        , 0.00392157, 0.6509804 , 0.2784314 , 0.5803922 ,\n",
              "       0.8980392 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.5019608 , 0.9647059 , 0.        ,\n",
              "       0.7607843 , 0.92156863, 0.04705882, 0.5568628 , 0.8       ,\n",
              "       0.        , 0.        , 0.36078432, 0.972549  , 0.06666667,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.64705884, 0.827451  , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09803922, 0.32941177, 0.        , 0.11764706, 0.5529412 ,\n",
              "       0.02352941, 0.00392157, 0.02745098, 0.        , 0.        ,\n",
              "       0.        , 0.02745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.8       , 0.75686276, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.7176471 , 0.4       ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb70CbLVyK65"
      },
      "source": [
        "## Build Your Baseline Model\n",
        "Some Hints:\n",
        "\n",
        "\n",
        "*  Model should have 784 input values (like mnist)\n",
        "*  Use `sparse_categorical_crossentropy` as your loss function.\n",
        "* You need 10 neurons in your last layer for output\n",
        "* You can add as many hidden layers with as many neurons in them as you like. \n",
        "* Limit your model epochs to 30 each time you fit.\n",
        "* You can use the `validation_split` command to automatically create a training / validation dataset.  Specify a percentage such as .2 in your fit statement. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWblzsMyNkU"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZjUVDIu4FF5",
        "outputId": "b4c70764-f59c-4a0a-82f1-457390cde077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Instantiate the model\n",
        "model = Sequential([\n",
        "                    Flatten(input_shape=(28, 28)),\n",
        "                    Dense(64, activation='relu'),\n",
        "                    Dense(32, activation='relu'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 52,650\n",
            "Trainable params: 52,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjEdTwjwAfvN",
        "outputId": "457c85f2-8c42-4990-f79d-edce190ed2e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "baseline = model.fit(X, y,\n",
        "                     epochs=30,\n",
        "                     validation_split=0.2,\n",
        "                     validation_data=(X, y))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
            "2495/2500 [============================>.] - ETA: 0s - loss: 9.7991 - accuracy: 0.0997WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 9.7841 - accuracy: 0.0998 - val_loss: 2.3081 - val_accuracy: 0.0990\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3122 - accuracy: 0.0985 - val_loss: 2.3039 - val_accuracy: 0.0984\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3034 - accuracy: 0.0984 - val_loss: 2.3041 - val_accuracy: 0.0984\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3030 - accuracy: 0.0992 - val_loss: 2.3041 - val_accuracy: 0.0983\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3028 - accuracy: 0.1006 - val_loss: 2.3041 - val_accuracy: 0.0970\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3120 - accuracy: 0.1001 - val_loss: 2.3040 - val_accuracy: 0.0990\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0992 - val_loss: 2.3040 - val_accuracy: 0.0990\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0985 - val_loss: 2.3040 - val_accuracy: 0.0990\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0996 - val_loss: 2.3042 - val_accuracy: 0.0983\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0988 - val_loss: 2.3041 - val_accuracy: 0.0970\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.1004 - val_loss: 2.3041 - val_accuracy: 0.0984\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.1006 - val_loss: 2.3040 - val_accuracy: 0.0979\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.1005 - val_loss: 2.3042 - val_accuracy: 0.0970\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0996 - val_loss: 2.3042 - val_accuracy: 0.0979\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0995 - val_loss: 2.3040 - val_accuracy: 0.0970\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0997 - val_loss: 2.3040 - val_accuracy: 0.0970\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0972 - val_loss: 2.3040 - val_accuracy: 0.0970\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.1008 - val_loss: 2.3041 - val_accuracy: 0.0999\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0997 - val_loss: 2.3040 - val_accuracy: 0.0984\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0981 - val_loss: 2.3039 - val_accuracy: 0.1035\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0987 - val_loss: 2.3041 - val_accuracy: 0.0984\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0989 - val_loss: 2.3041 - val_accuracy: 0.0984\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0990 - val_loss: 2.3040 - val_accuracy: 0.1021\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0983 - val_loss: 2.3040 - val_accuracy: 0.0970\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0993 - val_loss: 2.3041 - val_accuracy: 0.0984\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.1008 - val_loss: 2.3040 - val_accuracy: 0.0984\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0989 - val_loss: 2.3041 - val_accuracy: 0.0970\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0996 - val_loss: 2.3039 - val_accuracy: 0.1019\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0976 - val_loss: 2.3040 - val_accuracy: 0.0984\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3025 - accuracy: 0.0998 - val_loss: 2.3040 - val_accuracy: 0.0990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0QJURWh-9uv"
      },
      "source": [
        "### Visualize the results\n",
        "\n",
        "Create charts for both loss and accuracy by epoch. Use line graphs for both charts. Analyze the results. \n",
        "\n",
        "At what point should we have stopped training the model and why? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KONJtU5wqlXf",
        "outputId": "c16ebe73-bc52-48dc-f950-e315f4dc6f61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "baseline.history"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.09976249933242798,\n",
              "  0.0984874963760376,\n",
              "  0.09838750213384628,\n",
              "  0.09917499870061874,\n",
              "  0.10061249881982803,\n",
              "  0.10008750110864639,\n",
              "  0.09923750162124634,\n",
              "  0.09849999845027924,\n",
              "  0.09956250339746475,\n",
              "  0.09884999692440033,\n",
              "  0.10043749958276749,\n",
              "  0.10063750296831131,\n",
              "  0.10045000165700912,\n",
              "  0.09960000216960907,\n",
              "  0.09947499632835388,\n",
              "  0.09969999641180038,\n",
              "  0.09721250087022781,\n",
              "  0.10077500343322754,\n",
              "  0.09965000301599503,\n",
              "  0.09811250120401382,\n",
              "  0.09866250306367874,\n",
              "  0.09889999777078629,\n",
              "  0.09898749738931656,\n",
              "  0.09827499836683273,\n",
              "  0.09934999793767929,\n",
              "  0.10077500343322754,\n",
              "  0.09886249899864197,\n",
              "  0.09963750094175339,\n",
              "  0.09757500141859055,\n",
              "  0.09981250017881393],\n",
              " 'loss': [9.784072875976562,\n",
              "  2.3121800422668457,\n",
              "  2.3034160137176514,\n",
              "  2.3029844760894775,\n",
              "  2.302762508392334,\n",
              "  2.3119895458221436,\n",
              "  2.302495002746582,\n",
              "  2.3025221824645996,\n",
              "  2.3025076389312744,\n",
              "  2.302518129348755,\n",
              "  2.3025050163269043,\n",
              "  2.302499294281006,\n",
              "  2.3025004863739014,\n",
              "  2.3025059700012207,\n",
              "  2.3025107383728027,\n",
              "  2.302506923675537,\n",
              "  2.3025074005126953,\n",
              "  2.3024864196777344,\n",
              "  2.302520990371704,\n",
              "  2.302476644515991,\n",
              "  2.302502155303955,\n",
              "  2.30251145362854,\n",
              "  2.302502393722534,\n",
              "  2.302511692047119,\n",
              "  2.302504301071167,\n",
              "  2.3025062084198,\n",
              "  2.3024981021881104,\n",
              "  2.3025083541870117,\n",
              "  2.302520275115967,\n",
              "  2.302485942840576],\n",
              " 'val_accuracy': [0.0989999994635582,\n",
              "  0.09839999675750732,\n",
              "  0.09839999675750732,\n",
              "  0.09830000251531601,\n",
              "  0.09700000286102295,\n",
              "  0.0989999994635582,\n",
              "  0.0989999994635582,\n",
              "  0.0989999994635582,\n",
              "  0.09830000251531601,\n",
              "  0.09700000286102295,\n",
              "  0.09839999675750732,\n",
              "  0.097850002348423,\n",
              "  0.09700000286102295,\n",
              "  0.097850002348423,\n",
              "  0.09700000286102295,\n",
              "  0.09700000286102295,\n",
              "  0.09700000286102295,\n",
              "  0.09989999979734421,\n",
              "  0.09839999675750732,\n",
              "  0.10350000113248825,\n",
              "  0.09839999675750732,\n",
              "  0.09839999675750732,\n",
              "  0.10209999978542328,\n",
              "  0.09700000286102295,\n",
              "  0.09839999675750732,\n",
              "  0.09839999675750732,\n",
              "  0.09700000286102295,\n",
              "  0.10189999639987946,\n",
              "  0.09839999675750732,\n",
              "  0.0989999994635582],\n",
              " 'val_loss': [2.3080508708953857,\n",
              "  2.303922176361084,\n",
              "  2.3041024208068848,\n",
              "  2.3040640354156494,\n",
              "  2.3040645122528076,\n",
              "  2.3039989471435547,\n",
              "  2.3040387630462646,\n",
              "  2.303988218307495,\n",
              "  2.304152727127075,\n",
              "  2.304126262664795,\n",
              "  2.3040895462036133,\n",
              "  2.303999423980713,\n",
              "  2.304185628890991,\n",
              "  2.30420184135437,\n",
              "  2.3040432929992676,\n",
              "  2.3040270805358887,\n",
              "  2.3040475845336914,\n",
              "  2.3040618896484375,\n",
              "  2.3039896488189697,\n",
              "  2.3038628101348877,\n",
              "  2.304070472717285,\n",
              "  2.304077386856079,\n",
              "  2.303999900817871,\n",
              "  2.304018020629883,\n",
              "  2.30407452583313,\n",
              "  2.3040080070495605,\n",
              "  2.3040876388549805,\n",
              "  2.303907871246338,\n",
              "  2.304007053375244,\n",
              "  2.303966522216797]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijAlzfYKAFaY",
        "outputId": "5f9b2205-cea1-416c-c4ee-935fecbea31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame.from_records(baseline.history)\n",
        "df['epoch'] = [i for i in range(df.shape[0])]\n",
        "\n",
        "ax = sns.lineplot(x='epoch', y='val_loss', data=df)\n",
        "ax = sns.lineplot(x='epoch', y='loss', data=df);"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FjPCymyJBvW"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAhBrcE4yOZe"
      },
      "source": [
        "## Change Optimizers\n",
        "Try using the keras `adam` optimizer instead of `sgd` in your model. Visualize the difference in validation loss between the models with different optimizers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIW_spOZ0cxy",
        "outputId": "4f31009f-df50-4634-f3ef-67c84532fcb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "adam = Adam()\n",
        "\n",
        "# Instantiate the model\n",
        "model = Sequential([\n",
        "                    Flatten(input_shape=(28, 28)),\n",
        "                    Dense(128, activation='sigmoid'),\n",
        "                    Dense(64, activation='sigmoid'),\n",
        "                    Dense(32, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 111,146\n",
            "Trainable params: 111,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg8Aa_vvAcjZ",
        "outputId": "6ebe7c5c-8924-46ce-c2d2-1c4ba4e4be16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "baseline = model.fit(X, y, \n",
        "                     epochs=30,\n",
        "                     validation_split=0.2,\n",
        "                     validation_data=(X, y))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
            "2497/2500 [============================>.] - ETA: 0s - loss: 0.9550 - accuracy: 0.7058WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9545 - accuracy: 0.7060 - val_loss: 8.1625 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.6734 - accuracy: 0.7883 - val_loss: 9.6229 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.6195 - accuracy: 0.8037 - val_loss: 10.6969 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5958 - accuracy: 0.8097 - val_loss: 11.9740 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5752 - accuracy: 0.8167 - val_loss: 13.0910 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5540 - accuracy: 0.8242 - val_loss: 14.5205 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5483 - accuracy: 0.8248 - val_loss: 15.6116 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5302 - accuracy: 0.8294 - val_loss: 16.8888 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.5133 - accuracy: 0.8355 - val_loss: 17.7166 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.5101 - accuracy: 0.8375 - val_loss: 18.5988 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5029 - accuracy: 0.8395 - val_loss: 19.4832 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4865 - accuracy: 0.8449 - val_loss: 19.9236 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4801 - accuracy: 0.8474 - val_loss: 20.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4775 - accuracy: 0.8485 - val_loss: 20.2992 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4750 - accuracy: 0.8479 - val_loss: 20.2620 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.4760 - accuracy: 0.8487 - val_loss: 20.0900 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4605 - accuracy: 0.8546 - val_loss: 20.6299 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4603 - accuracy: 0.8542 - val_loss: 20.6148 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.4507 - accuracy: 0.8576 - val_loss: 21.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4489 - accuracy: 0.8578 - val_loss: 20.9260 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4460 - accuracy: 0.8585 - val_loss: 21.1980 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4380 - accuracy: 0.8614 - val_loss: 20.8554 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4362 - accuracy: 0.8623 - val_loss: 21.0280 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4344 - accuracy: 0.8624 - val_loss: 21.3029 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4378 - accuracy: 0.8603 - val_loss: 21.1038 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4360 - accuracy: 0.8618 - val_loss: 21.1604 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4350 - accuracy: 0.8620 - val_loss: 21.6621 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4341 - accuracy: 0.8628 - val_loss: 21.6069 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4310 - accuracy: 0.8641 - val_loss: 21.7513 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.4255 - accuracy: 0.8644 - val_loss: 21.6914 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLpSFgwkbDNh",
        "outputId": "9463db99-da5e-40ea-93fb-1e4fc2404b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "df = pd.DataFrame.from_records(baseline.history)\n",
        "df['epoch'] = [i for i in range(df.shape[0])]\n",
        "\n",
        "ax = sns.lineplot(x='epoch', y='val_loss', data=df)\n",
        "ax = sns.lineplot(x='epoch', y='loss', data=df);"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJrbh3qryi4w"
      },
      "source": [
        "### Additional Written Tasks:\n",
        "In this section, you will need to search for resources: \n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzs4fd-RynDd"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Research convolutional neural networks and try including convolution layers in your network.\n",
        "- Pick two classes and make QuickDraw a binary classification problem, how does your model architecture change?\n",
        "- Implement Cross Validation model evaluation on your Quickdraw implementation \n",
        "\n",
        "Watch some more videos on Gradient Descent:\n",
        "- [Gradient Descent, Step-by-Step](https://www.youtube.com/watch?v=sDv4f4s2SB8)  by StatQuest w/ Josh Starmer. This will help you understand the gradient descent based optimization that happens underneath the hood of neural networks. It uses a non-neural network example, which I believe is a gentler introduction. You will hear me refer to this technique as \"vanilla\" gradient descent. \n",
        "- [Stochastic Gradient Descent, Clearly Explained!!!](https://www.youtube.com/watch?v=vMh0zPT0tLI) by StatQuest w/ Josh Starmer. This builds on the techniques in the previous video.  This technique is the one that is actually implemented inside modern 'nets. \n",
        "- [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)"
      ]
    }
  ]
}
